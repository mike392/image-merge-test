{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "from tf_pose import common\n",
    "from tf_pose.estimator import TfPoseEstimator\n",
    "from tf_pose.networks import get_graph_path\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "\n",
    "# Initialize pose estimator\n",
    "model = 'mobilenet_thin'  # You can choose other models like 'cmu'\n",
    "estimator = TfPoseEstimator(get_graph_path(model), target_size=(432, 368))\n",
    "\n",
    "# Load an image\n",
    "image_path = 'path_to_your_image.jpg'  # Replace with your image path\n",
    "image = common.read_imgfile(image_path, None, None)\n",
    "if image is None:\n",
    "    raise Exception('Image can not be read, path=%s' % image_path)\n",
    "\n",
    "# Estimate poses\n",
    "humans = estimator.inference(image)\n",
    "image = TfPoseEstimator.draw_humans(image, humans, imgcopy=False)\n",
    "\n",
    "# Show the image\n",
    "plt.imshow(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 57, 128, 164)\n",
      "(1, 19, 128, 164)\n",
      "(128, 164)\n",
      "(128, 164)\n",
      "(128, 164)\n",
      "(128, 164)\n",
      "(128, 164)\n",
      "(128, 164)\n",
      "(128, 164)\n",
      "(128, 164)\n",
      "(128, 164)\n",
      "(128, 164)\n",
      "(128, 164)\n",
      "(128, 164)\n",
      "(128, 164)\n",
      "(128, 164)\n",
      "(128, 164)\n",
      "(128, 164)\n",
      "(128, 164)\n",
      "(128, 164)\n",
      "(128, 164)\n"
     ]
    }
   ],
   "source": [
    "import cv2 as cv\n",
    "from keras.preprocessing import image\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "BODY_PARTS = { \"Nose\": 0, \"Neck\": 1, \"RShoulder\": 2, \"RElbow\": 3, \"RWrist\": 4,\n",
    "               \"LShoulder\": 5, \"LElbow\": 6, \"LWrist\": 7, \"RHip\": 8, \"RKnee\": 9,\n",
    "               \"RAnkle\": 10, \"LHip\": 11, \"LKnee\": 12, \"LAnkle\": 13, \"REye\": 14,\n",
    "               \"LEye\": 15, \"REar\": 16, \"LEar\": 17, \"Background\": 18 }\n",
    "\n",
    "POSE_PAIRS = [ [\"Neck\", \"RShoulder\"], [\"Neck\", \"LShoulder\"], [\"RShoulder\", \"RElbow\"],\n",
    "               [\"RElbow\", \"RWrist\"], [\"LShoulder\", \"LElbow\"], [\"LElbow\", \"LWrist\"],\n",
    "               [\"Neck\", \"RHip\"], [\"RHip\", \"RKnee\"], [\"RKnee\", \"RAnkle\"], [\"Neck\", \"LHip\"],\n",
    "               [\"LHip\", \"LKnee\"], [\"LKnee\", \"LAnkle\"], [\"Neck\", \"Nose\"], [\"Nose\", \"REye\"],\n",
    "               [\"REye\", \"REar\"], [\"Nose\", \"LEye\"], [\"LEye\", \"LEar\"] ]\n",
    "\n",
    "\n",
    "target_size = (1024, 1309)\n",
    "\n",
    "\n",
    "net = cv.dnn.readNetFromTensorflow(\"graph_opt.pb\")\n",
    "\n",
    "threshold=0.2\n",
    "\n",
    "# img = cv.imread('person_image.png',cv.IMREAD_UNCHANGED)\n",
    "img = Image.open('person_image.png')\n",
    "img = img.convert('RGB')\n",
    "cv.imshow(\"initial\", image.img_to_array(img))\n",
    "# img = img.crop(target_size[::-1], Image.Resampling.LANCZOS)\n",
    "# img = image.load_img(image_path, target_size=target_size)\n",
    "img_array = image.img_to_array(img)\n",
    "cropped_img_array = image.img_to_array(img.crop((0,0, 1024, 1024)))\n",
    "\n",
    "\n",
    "photo_height=cropped_img_array.shape[0]\n",
    "photo_width=cropped_img_array.shape[1]\n",
    "net.setInput(cv.dnn.blobFromImage(cropped_img_array, 1.0, (target_size[1], target_size[0]), (127.5, 127.5, 127.5), swapRB=True, crop=False))\n",
    "\n",
    "out = net.forward()\n",
    "print(out.shape)\n",
    "out = out[:, :19, :, :]\n",
    "print(out.shape)\n",
    "assert(len(BODY_PARTS) == out.shape[1])\n",
    "\n",
    "points = []\n",
    "for i in range(len(BODY_PARTS)):\n",
    "    # Slice heatmap of corresponging body's part.\n",
    "    heatMap = out[0, i, :, :]\n",
    "    print(heatMap.shape)\n",
    "    # Originally, we try to find all the local maximums. To simplify a sample\n",
    "    # we just find a global one. However only a single pose at the same time\n",
    "    # could be detected this way.\n",
    "    _, conf, _, point = cv.minMaxLoc(heatMap)\n",
    "    x = (photo_width * point[0]) / out.shape[3]\n",
    "    y = (photo_height * point[1]) / out.shape[2]\n",
    "    # Add a point if it's confidence is higher than threshold.\n",
    "    points.append((int(x), int(y)) if conf > threshold else None)\n",
    "\n",
    "\n",
    "for pair in POSE_PAIRS:\n",
    "    partFrom = pair[0]\n",
    "    partTo = pair[1]\n",
    "    assert(partFrom in BODY_PARTS)\n",
    "    assert(partTo in BODY_PARTS)\n",
    "\n",
    "    idFrom = BODY_PARTS[partFrom]\n",
    "    idTo = BODY_PARTS[partTo]\n",
    "\n",
    "    if points[idFrom] and points[idTo]:\n",
    "        cv.line(cropped_img_array, points[idFrom], points[idTo], (0, 255, 0), 3)\n",
    "        cv.ellipse(cropped_img_array, points[idFrom], (3, 3), 0, 0, 360, (0, 0, 255), cv.FILLED)\n",
    "        cv.ellipse(cropped_img_array, points[idTo], (3, 3), 0, 0, 360, (0, 0, 255), cv.FILLED)\n",
    "\n",
    "t, _ = net.getPerfProfile()\n",
    "\n",
    "cv.imshow(\"cool\",img_array)\n",
    "\n",
    "#waits for user to press any key \n",
    "#(this is necessary to avoid Python kernel form crashing)\n",
    "cv.waitKey(0)\n",
    "\n",
    "#closing all open windows \n",
    "cv.destroyAllWindows() "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-24T19:22:12.932962Z",
     "start_time": "2024-01-24T19:22:06.891447Z"
    }
   },
   "id": "c612fcd7f83d5204"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "5a72b89216e3dfdc"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
